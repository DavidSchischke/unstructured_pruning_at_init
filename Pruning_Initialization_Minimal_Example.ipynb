{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "klTA5EkRI_33"
      },
      "outputs": [],
      "source": [
        "from time import time \n",
        "from copy import deepcopy\n",
        "\n",
        "import torch\n",
        "import numpy as np \n",
        "\n",
        "from torch import nn\n",
        "\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from torch.optim import Adam\n",
        "from torch.nn.utils import prune\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from torchvision import models\n",
        "from torchvision.datasets.cifar import CIFAR10\n",
        "from torchvision.transforms import ToTensor, Lambda\n",
        "\n",
        "from tqdm import tqdm\n",
        "from scipy.stats import ttest_ind\n",
        "\n",
        "# Note: I ran this on a GPU instance\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TybJEzl4I_34"
      },
      "source": [
        "# Loading the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ByhDoxJLI_36"
      },
      "outputs": [],
      "source": [
        "def load_CIFAR10(batch_size: int = 128, shuffle: bool = True): \n",
        "    \"\"\"Load CIFAR10 data from memory\"\"\"\n",
        "    \n",
        "    try: \n",
        "        train = CIFAR10(\n",
        "            root = \"data\", \n",
        "            train = True,\n",
        "            download=False,\n",
        "            transform = ToTensor(), \n",
        "            target_transform=Lambda(lambda y: torch.zeros(10, dtype=torch.float).scatter_(0, torch.tensor(y), value=1))\n",
        "        )\n",
        "        \n",
        "        test = CIFAR10(\n",
        "            root = \"data\", \n",
        "            train = False,\n",
        "            download=False,\n",
        "            transform = ToTensor(), \n",
        "            target_transform=Lambda(lambda y: torch.zeros(10, dtype=torch.float).scatter_(0, torch.tensor(y), value=1))\n",
        "        )\n",
        "    except: \n",
        "        train = CIFAR10(\n",
        "            root = \"data\", \n",
        "            train = True,\n",
        "            download = True,\n",
        "            transform = ToTensor(), \n",
        "            target_transform=Lambda(lambda y: torch.zeros(10, dtype=torch.float).scatter_(0, torch.tensor(y), value=1))\n",
        "        )\n",
        "        \n",
        "        test = CIFAR10(\n",
        "            root = \"data\", \n",
        "            train = False,\n",
        "            download =True,\n",
        "            transform = ToTensor(), \n",
        "            target_transform=Lambda(lambda y: torch.zeros(10, dtype=torch.float).scatter_(0, torch.tensor(y), value=1))\n",
        "        )\n",
        "        \n",
        "    train_data = DataLoader(train, batch_size=batch_size, shuffle=shuffle)\n",
        "    test_data  = DataLoader(test, batch_size=batch_size, shuffle=shuffle)\n",
        "    \n",
        "    return train_data, test_data\n",
        "\n",
        "train_data, test_data = load_CIFAR10()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uaDp27i3I_36"
      },
      "source": [
        "# Defining Train and Test Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t7L4gEifI_36"
      },
      "outputs": [],
      "source": [
        "def train(train_data, model, loss_func, optim): \n",
        "    \"\"\"Apply one step of training\"\"\"\n",
        "    size = len(train_data.dataset)\n",
        "    for batch, (X, y) in enumerate(train_data):\n",
        "        X, y = X.to(DEVICE), y.to(DEVICE)\n",
        "\n",
        "        pred = model(X)\n",
        "        loss = loss_func(pred, y)\n",
        "        \n",
        "        # Optimization \n",
        "        optim.zero_grad() \n",
        "        loss.backward()\n",
        "        optim.step()\n",
        "\n",
        "def test(test_data, model, loss_func, optim):\n",
        "    \"\"\"Evaluate the model on the test set\"\"\"\n",
        "    size = len(test_data.dataset)\n",
        "    n_batch = len(test_data)\n",
        "    test_loss, correct = 0, 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for X, y in test_data:\n",
        "            X, y = X.to(DEVICE), y.to(DEVICE)\n",
        "            y_hat = model(X)\n",
        "            test_loss += loss_func(y_hat, y).item()\n",
        "            \n",
        "            correct += (y_hat.argmax(1) == y.argmax(1)).type(torch.float).sum().item()\n",
        "            \n",
        "    test_loss /= n_batch\n",
        "    correct /= size \n",
        "    \n",
        "    print(f\"Accuracy: {100*correct:>0.1f}%, Avg loss: {test_loss:>8f}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BSgDgIo1I_37"
      },
      "source": [
        "# Defining the pruning methods"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a4W6Zc9KI_37"
      },
      "outputs": [],
      "source": [
        "LAYERS = [\"conv\", \"linear\"]\n",
        "\n",
        "def prune_resnet(model, ratio): \n",
        "  \"\"\"\n",
        "  Iterate through layers of the model and prune linear and conv layers. This is\n",
        "  a very basic approach corresponding to magnitude based pruning at initialization,\n",
        "  which is used as a baseline in many papers. \n",
        "  \"\"\"\n",
        "  \n",
        "  for name, layer in model.named_modules():\n",
        "    if any(x in name for x in LAYERS):\n",
        "      prune.l1_unstructured(layer, name = \"weight\", amount = ratio)\n",
        "      if hasattr(layer, \"bias\") and layer.bias != None:\n",
        "          prune.l1_unstructured(layer, name = \"bias\", amount = ratio)\n",
        "\n",
        "  return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQjizI_SI_37"
      },
      "source": [
        "# Evaluate pruning training efficiency"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SuEgszpYI_37"
      },
      "outputs": [],
      "source": [
        "def eval_training(model, niter):\n",
        "  \"\"\"Train a model for a fixed number of iterations.\"\"\"\n",
        "  loss = CrossEntropyLoss()\n",
        "  optim = Adam(model.parameters(), lr = 1e-3)\n",
        "\n",
        "  exec_time = []\n",
        "\n",
        "  for e in tqdm(range(niter)): \n",
        "    start = time()\n",
        "    train(train_data, model, loss, optim)\n",
        "    end = time()\n",
        "    exec_time.append(end-start)\n",
        "  \n",
        "  test(test_data, model, loss, optim)\n",
        "  \n",
        "  return exec_time, model\n",
        "\n",
        "def compare_training_time(model, niter = 10, ratio = 0.6):\n",
        "  \"\"\"\n",
        "  Create a deepcopy of the ResNet model and prune it. Then train \n",
        "  both models for a fixed number of iterations and print the  \n",
        "  \"\"\"\n",
        "  model_prune = prune_resnet(deepcopy(model), ratio = ratio)\n",
        "\n",
        "  print(\"### Unpruned training ###\")\n",
        "  exec_time_t, model_t = eval_training(model, niter)\n",
        "  \n",
        "  print(\"### Pruned training ###\")\n",
        "  exec_time_pt, model_pt = eval_training(model_prune, niter)\n",
        "\n",
        "  tval, pval = ttest_ind(exec_time_t, exec_time_pt)\n",
        "\n",
        "  print(f\"Unpruned: M = {np.round(np.mean(exec_time_t), 4)}, SD = {np.round(np.std(exec_time_t), 4)}\")\n",
        "  print(f\"Pruned: M = {np.round(np.mean(exec_time_pt), 4)}, SD = {np.round(np.std(exec_time_pt), 4)}\")\n",
        "  \n",
        "  if pval < .05: \n",
        "    print(f\"Pruning leads to a statistical significance in training time: t = {np.round(tval, 4)}, p = {np.round(pval, 4)}\")\n",
        "  else: \n",
        "    print(f\"Pruning does not lead to a statistical significance in training time: t = {np.round(tval, 4)}, p = {np.round(pval, 4)}\")\n",
        "\n",
        "  return model_t, model_pt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FFgWI3bxI_38",
        "outputId": "bc3155ad-c1f7-4f65-ce70-9af2d6aa889d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### Unpruned training ###\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [09:18<00:00, 27.90s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 61.6%, Avg loss: 1.168145\n",
            "\n",
            "### Pruned training ###\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [09:34<00:00, 28.71s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 71.3%, Avg loss: 0.871094\n",
            "\n",
            "Unpruned: M = 27.8995, SD = 1.1458\n",
            "Pruned: M = 28.7073, SD = 0.1553\n",
            "Pruning leads to a statistical significance in training time: t = -3.0449, p = 0.0042\n"
          ]
        }
      ],
      "source": [
        "testnet = models.resnet50(num_classes = 10).to(DEVICE)\n",
        "\n",
        "model_t, model_pt = compare_training_time(testnet, niter = 20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gO4oZ7HHI_38"
      },
      "source": [
        "# Evaluate pruning inference efficiency"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OwbV1U1nI_38"
      },
      "outputs": [],
      "source": [
        "def eval_inference(model, niter = 10): \n",
        "  \"\"\"\n",
        "  Get the time required for inference on the full test set for a fixed \n",
        "  number of iterations.\n",
        "  \"\"\"\n",
        "  duration = []\n",
        "  for i in tqdm(range(niter)):\n",
        "    start = time()\n",
        "    for batch in train_data:\n",
        "      with torch.no_grad():\n",
        "        data = batch[0].to(DEVICE) \n",
        "        model(data)\n",
        "    stop = time()\n",
        "    duration.append(stop - start)\n",
        "  return duration \n",
        "\n",
        "def compare_inference_time(model_t, model_pt, niter = 20):\n",
        "  \"\"\"\n",
        "  Use the trained models without/with pruning for inference by running\n",
        "  the full training set for a fixed number of iterations. \n",
        "  \"\"\"\n",
        "\n",
        "  print(\"### Unpruned inference ###\")\n",
        "  exec_time_t = eval_inference(model_t, niter)\n",
        "  \n",
        "  print(\"### Pruned inference ###\")\n",
        "  exec_time_pt = eval_inference(model_pt, niter)\n",
        "\n",
        "  tval, pval = ttest_ind(exec_time_t, exec_time_pt)\n",
        "\n",
        "  print(f\"Unpruned: M = {np.round(np.mean(exec_time_t), 4)}, SD = {np.round(np.std(exec_time_t), 4)}\")\n",
        "  print(f\"Pruned: M = {np.round(np.mean(exec_time_pt), 4)}, SD = {np.round(np.std(exec_time_pt), 4)}\")\n",
        "\n",
        "  if pval < .05: \n",
        "    print(f\"Pruning leads to a statistical significance in inference time: t = {np.round(tval, 4)}, p = {np.round(pval, 4)}\")\n",
        "  else: \n",
        "    print(f\"Pruning does not lead to a statistical significance in inferences time: t = {np.round(tval, 4)}, p = {np.round(pval, 4)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VK7JUfR0I_38",
        "outputId": "34c44b85-62ba-45c5-ff41-0531595dbab1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### Unpruned inference ###\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [03:45<00:00, 11.27s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### Pruned inference ###\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [04:03<00:00, 12.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unpruned: M = 11.2734, SD = 0.374\n",
            "Pruned: M = 12.178, SD = 0.1735\n",
            "Pruning leads to a statistical significance in inference time: t = -9.5652, p = 0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "compare_inference_time(model_t, model_pt)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "torch",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.15"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "3e88cdac7d2e701fef9292495ee6bd750d2abc055387fdaf3b76ef9c7a6be88f"
      }
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}